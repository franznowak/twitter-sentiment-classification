{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a79d67df",
   "metadata": {},
   "source": [
    "## Naive Bayes Baseline Classifier\n",
    "\n",
    "See [Jurafsky and Martin](https://web.stanford.edu/~jurafsky/slp3/4.pdf) for details on Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5a56b5",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "In order to get useful probabilities for Naive Bayes, lemmatize the tweets, then create the vocabulary and collect them into BoW form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83259de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/franz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/franz/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from loading import load_train\n",
    "from preprocessing import remove_tags\n",
    "from preprocessing import tokenize\n",
    "from preprocessing import remove_stopwords\n",
    "from preprocessing import lemmatize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53427f57",
   "metadata": {},
   "source": [
    "Preprocess tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64729762",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_train(full=True)\n",
    "remove_tags(df)\n",
    "tokenize(df)\n",
    "remove_stopwords(df)\n",
    "lemmatize(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cfc5e0",
   "metadata": {},
   "source": [
    "### Training the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3f203e",
   "metadata": {},
   "source": [
    "Class probabilities $P(c)$ are fixed in our task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61e5797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = {\"pos\": 0.5, \"neg\": 0.5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997c0909",
   "metadata": {},
   "source": [
    "Collect the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a30719b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578234"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set([word for sentence in df.x for word in sentence])\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6554b7",
   "metadata": {},
   "source": [
    "Create one big document of words divided by class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b963a4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdoc = {}\n",
    "bigdoc[\"pos\"] = [word for sentence in df.loc[df['y'] == 1].x for word in sentence]\n",
    "bigdoc[\"neg\"] = [word for sentence in df.loc[df['y'] == 0].x for word in sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397f8cc3",
   "metadata": {},
   "source": [
    "Count the number of occurrences of each word per class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9639b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = {\"pos\":{}, \"neg\":{}}\n",
    "for word in vocabulary:\n",
    "    count[\"pos\"][word] = 0\n",
    "    count[\"neg\"][word] = 0\n",
    "\n",
    "for word in bigdoc[\"pos\"]:\n",
    "    count[\"pos\"][word] += 1\n",
    "for word in bigdoc[\"neg\"]:\n",
    "    count[\"neg\"][word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05b0311",
   "metadata": {},
   "source": [
    "MLE of word probability given a class (with Laplace smoothing):\n",
    "$\\hat P(w_i|c) = \\frac{count(w_i,c)+1}{\\sum_{w\\in W}(count(w,c)+1)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89c2933",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = {}\n",
    "for word in vocabulary:\n",
    "    likelihood[word] = {}\n",
    "    likelihood[word][\"pos\"] = (count[\"pos\"][word] + 1) / (len(bigdoc[\"pos\"]) + len(vocabulary))\n",
    "    likelihood[word][\"neg\"] = (count[\"neg\"][word] + 1) / (len(bigdoc[\"neg\"]) + len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0da373",
   "metadata": {},
   "source": [
    "### Predictions on Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d375dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def classify_preprocessed_sentence(tokens, prior, likelihood, classes, vocab):\n",
    "    ssum = {}\n",
    "    for sentiment in classes:\n",
    "        ssum[sentiment] = np.log(prior[sentiment])\n",
    "        for word in tokens:\n",
    "            if word in vocabulary:\n",
    "                ssum[sentiment] += np.log(likelihood[word][sentiment])\n",
    "    return max(ssum, key=ssum.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b6cd2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_pred'] = df.x.apply(lambda tokens: 1 if classify_preprocessed_sentence(tokens, prior, likelihood, [\"pos\",\"neg\"], vocabulary) == \"pos\" else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33f5d9e",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b40b6a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "from evaluation import evaluate\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d8a7de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(df['y'])\n",
    "y_pred = torch.tensor(df['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7245d3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:---\n",
      "* accuracy: 0.753086\n",
      "* precision: 0.6893940074247157\n",
      "* recall: 0.9212328\n",
      "* f1: 0.7886275937236656\n",
      "* bce: 8.528273375547503\n",
      "* auc: 0.7530859999999999\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.753086,\n",
       " 0.6893940074247157,\n",
       " 0.9212328,\n",
       " 0.7886275937236656,\n",
       " 8.528273375547503,\n",
       " 0.7530859999999999)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f2afe0",
   "metadata": {},
   "source": [
    "### Predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b21af054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loading import load_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "239ef142",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = load_test()\n",
    "remove_tags(df2)\n",
    "tokenize(df2)\n",
    "remove_stopwords(df2)\n",
    "lemmatize(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46fe8263",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Prediction'] = df2.x.apply(lambda tokens: 1 if classify_preprocessed_sentence(tokens, prior, likelihood, [\"pos\",\"neg\"], vocabulary) == \"pos\" else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f13ec148",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"naive_bayes.csv\", columns=['Prediction'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
