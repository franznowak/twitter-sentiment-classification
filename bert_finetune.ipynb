{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/fionamuntwyler/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/fionamuntwyler/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/fionamuntwyler/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from bert import *\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "FULL = False\n",
    "FORCE = True\n",
    "\n",
    "MODEL = 'distilbert-base-uncased'\n",
    "TOKENIZER = 'bert-base-uncased'\n",
    "FT = 'CLASS_LNORM'  # mode of fine-tuning\n",
    "# 'CLASS_LNORM': train classifier and layer norm parameters\n",
    "# 'PREC_CLASS': pre-classifier and classifier\n",
    "\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "IDENT = '_'.join([MODEL, \"ep\", str(EPOCHS), \"bs\", str(BATCH_SIZE), str(FT)])\n",
    "DIR = \"bert_data/\" + IDENT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(DIR)\n",
    "except FileExistsError:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Casting the dataset:   0%|          | 0/16 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dae0ef980cb7449b8664ed84b077716b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Casting the dataset:   0%|          | 0/4 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2229c9c4f2a45dbbee0e800e66251da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.fingerprint:Parameter 'function'=<function tokenize.<locals>.tokenize_function at 0x13238c160> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/160 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5bbeed0159449eaadf459118a232e1d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/40 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4114eb7e3f3a40619134b154f66dc885"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_train, dataset_val = load()\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER)\n",
    "train_tokenized = tokenize(\n",
    "    dataset_train,\n",
    "    tokenizer,\n",
    "    path=f'bert/cache/train_tokenized__{TOKENIZER}{\"__full\" if FULL else \"\"}',\n",
    "    force=FORCE)\n",
    "val_tokenized = tokenize(\n",
    "    dataset_val,\n",
    "    tokenizer,\n",
    "    path=f'bert/cache/val_tokenized__{TOKENIZER}{\"__full\" if FULL else \"\"}',\n",
    "    force=FORCE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model = get_BERT(MODEL, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "req_grad = 0\n",
    "not_grad = 0\n",
    "for param in model.distilbert.parameters():\n",
    "    if param.requires_grad:\n",
    "        req_grad+=1\n",
    "    else:\n",
    "        not_grad+=1\n",
    "print(req_grad)\n",
    "print(not_grad)\n",
    "\n",
    "req_grad = 0\n",
    "not_grad = 0\n",
    "for param in model.pre_classifier.parameters():\n",
    "    if param.requires_grad:\n",
    "        req_grad+=1\n",
    "    else:\n",
    "        not_grad+=1\n",
    "print(req_grad)\n",
    "print(not_grad)\n",
    "\n",
    "req_grad = 0\n",
    "not_grad = 0\n",
    "for param in model.classifier.parameters():\n",
    "    if param.requires_grad:\n",
    "        req_grad+=1\n",
    "    else:\n",
    "        not_grad+=1\n",
    "print(req_grad)\n",
    "print(not_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "for param in model.pre_classifier.parameters():\n",
    "    param.requires_grad = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "for param in model.pre_classifier.parameters():\n",
    "    param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Trainable Parameters\", \"Parameters\"])\n",
    "    total_params_train = 0\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        params = parameter.numel()\n",
    "        params_t = params\n",
    "        if not parameter.requires_grad:\n",
    "            params_t = 0\n",
    "        table.add_row([name, params_t, params])\n",
    "        total_params_train+=params_t\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params_train}\")\n",
    "    pourcent = float(total_params_train)/total_params\n",
    "    print(f\"Percentage of trainable parameters: {pourcent}\")\n",
    "\n",
    "    return total_params_train, pourcent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def set_trainable(model):\n",
    "    count = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if \"layer_norm\" in str(name) or \"LayerNorm\" in str(name):\n",
    "            count+=1\n",
    "            parameter.requires_grad = True\n",
    "\n",
    "    print(count)\n",
    "    return count_parameters(model)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "+---------------------------------------------------------+----------------------+------------+\n",
      "|                         Modules                         | Trainable Parameters | Parameters |\n",
      "+---------------------------------------------------------+----------------------+------------+\n",
      "|       distilbert.embeddings.word_embeddings.weight      |          0           |  23440896  |\n",
      "|     distilbert.embeddings.position_embeddings.weight    |          0           |   393216   |\n",
      "|          distilbert.embeddings.LayerNorm.weight         |         768          |    768     |\n",
      "|           distilbert.embeddings.LayerNorm.bias          |         768          |    768     |\n",
      "|  distilbert.transformer.layer.0.attention.q_lin.weight  |          0           |   589824   |\n",
      "|   distilbert.transformer.layer.0.attention.q_lin.bias   |          0           |    768     |\n",
      "|  distilbert.transformer.layer.0.attention.k_lin.weight  |          0           |   589824   |\n",
      "|   distilbert.transformer.layer.0.attention.k_lin.bias   |          0           |    768     |\n",
      "|  distilbert.transformer.layer.0.attention.v_lin.weight  |          0           |   589824   |\n",
      "|   distilbert.transformer.layer.0.attention.v_lin.bias   |          0           |    768     |\n",
      "| distilbert.transformer.layer.0.attention.out_lin.weight |          0           |   589824   |\n",
      "|  distilbert.transformer.layer.0.attention.out_lin.bias  |          0           |    768     |\n",
      "|   distilbert.transformer.layer.0.sa_layer_norm.weight   |         768          |    768     |\n",
      "|    distilbert.transformer.layer.0.sa_layer_norm.bias    |         768          |    768     |\n",
      "|      distilbert.transformer.layer.0.ffn.lin1.weight     |          0           |  2359296   |\n",
      "|       distilbert.transformer.layer.0.ffn.lin1.bias      |          0           |    3072    |\n",
      "|      distilbert.transformer.layer.0.ffn.lin2.weight     |          0           |  2359296   |\n",
      "|       distilbert.transformer.layer.0.ffn.lin2.bias      |          0           |    768     |\n",
      "| distilbert.transformer.layer.0.output_layer_norm.weight |         768          |    768     |\n",
      "|  distilbert.transformer.layer.0.output_layer_norm.bias  |         768          |    768     |\n",
      "|  distilbert.transformer.layer.1.attention.q_lin.weight  |          0           |   589824   |\n",
      "|   distilbert.transformer.layer.1.attention.q_lin.bias   |          0           |    768     |\n",
      "|  distilbert.transformer.layer.1.attention.k_lin.weight  |          0           |   589824   |\n",
      "|   distilbert.transformer.layer.1.attention.k_lin.bias   |          0           |    768     |\n",
      "|  distilbert.transformer.layer.1.attention.v_lin.weight  |          0           |   589824   |\n",
      "|   distilbert.transformer.layer.1.attention.v_lin.bias   |          0           |    768     |\n",
      "| distilbert.transformer.layer.1.attention.out_lin.weight |          0           |   589824   |\n",
      "|  distilbert.transformer.layer.1.attention.out_lin.bias  |          0           |    768     |\n",
      "|   distilbert.transformer.layer.1.sa_layer_norm.weight   |         768          |    768     |\n",
      "|    distilbert.transformer.layer.1.sa_layer_norm.bias    |         768          |    768     |\n",
      "|      distilbert.transformer.layer.1.ffn.lin1.weight     |          0           |  2359296   |\n",
      "|       distilbert.transformer.layer.1.ffn.lin1.bias      |          0           |    3072    |\n",
      "|      distilbert.transformer.layer.1.ffn.lin2.weight     |          0           |  2359296   |\n",
      "|       distilbert.transformer.layer.1.ffn.lin2.bias      |          0           |    768     |\n",
      "| distilbert.transformer.layer.1.output_layer_norm.weight |         768          |    768     |\n",
      "|  distilbert.transformer.layer.1.output_layer_norm.bias  |         768          |    768     |\n",
      "|  distilbert.transformer.layer.2.attention.q_lin.weight  |          0           |   589824   |\n",
      "|   distilbert.transformer.layer.2.attention.q_lin.bias   |          0           |    768     |\n",
      "|  distilbert.transformer.layer.2.attention.k_lin.weight  |          0           |   589824   |\n",
      "|   distilbert.transformer.layer.2.attention.k_lin.bias   |          0           |    768     |\n",
      "|  distilbert.transformer.layer.2.attention.v_lin.weight  |          0           |   589824   |\n",
      "|   distilbert.transformer.layer.2.attention.v_lin.bias   |          0           |    768     |\n",
      "| distilbert.transformer.layer.2.attention.out_lin.weight |          0           |   589824   |\n",
      "|  distilbert.transformer.layer.2.attention.out_lin.bias  |          0           |    768     |\n",
      "|   distilbert.transformer.layer.2.sa_layer_norm.weight   |         768          |    768     |\n",
      "|    distilbert.transformer.layer.2.sa_layer_norm.bias    |         768          |    768     |\n",
      "|      distilbert.transformer.layer.2.ffn.lin1.weight     |          0           |  2359296   |\n",
      "|       distilbert.transformer.layer.2.ffn.lin1.bias      |          0           |    3072    |\n",
      "|      distilbert.transformer.layer.2.ffn.lin2.weight     |          0           |  2359296   |\n",
      "|       distilbert.transformer.layer.2.ffn.lin2.bias      |          0           |    768     |\n",
      "| distilbert.transformer.layer.2.output_layer_norm.weight |         768          |    768     |\n",
      "|  distilbert.transformer.layer.2.output_layer_norm.bias  |         768          |    768     |\n",
      "|  distilbert.transformer.layer.3.attention.q_lin.weight  |          0           |   589824   |\n",
      "|   distilbert.transformer.layer.3.attention.q_lin.bias   |          0           |    768     |\n",
      "|  distilbert.transformer.layer.3.attention.k_lin.weight  |          0           |   589824   |\n",
      "|   distilbert.transformer.layer.3.attention.k_lin.bias   |          0           |    768     |\n",
      "|  distilbert.transformer.layer.3.attention.v_lin.weight  |          0           |   589824   |\n",
      "|   distilbert.transformer.layer.3.attention.v_lin.bias   |          0           |    768     |\n",
      "| distilbert.transformer.layer.3.attention.out_lin.weight |          0           |   589824   |\n",
      "|  distilbert.transformer.layer.3.attention.out_lin.bias  |          0           |    768     |\n",
      "|   distilbert.transformer.layer.3.sa_layer_norm.weight   |         768          |    768     |\n",
      "|    distilbert.transformer.layer.3.sa_layer_norm.bias    |         768          |    768     |\n",
      "|      distilbert.transformer.layer.3.ffn.lin1.weight     |          0           |  2359296   |\n",
      "|       distilbert.transformer.layer.3.ffn.lin1.bias      |          0           |    3072    |\n",
      "|      distilbert.transformer.layer.3.ffn.lin2.weight     |          0           |  2359296   |\n",
      "|       distilbert.transformer.layer.3.ffn.lin2.bias      |          0           |    768     |\n",
      "| distilbert.transformer.layer.3.output_layer_norm.weight |         768          |    768     |\n",
      "|  distilbert.transformer.layer.3.output_layer_norm.bias  |         768          |    768     |\n",
      "|  distilbert.transformer.layer.4.attention.q_lin.weight  |          0           |   589824   |\n",
      "|   distilbert.transformer.layer.4.attention.q_lin.bias   |          0           |    768     |\n",
      "|  distilbert.transformer.layer.4.attention.k_lin.weight  |          0           |   589824   |\n",
      "|   distilbert.transformer.layer.4.attention.k_lin.bias   |          0           |    768     |\n",
      "|  distilbert.transformer.layer.4.attention.v_lin.weight  |          0           |   589824   |\n",
      "|   distilbert.transformer.layer.4.attention.v_lin.bias   |          0           |    768     |\n",
      "| distilbert.transformer.layer.4.attention.out_lin.weight |          0           |   589824   |\n",
      "|  distilbert.transformer.layer.4.attention.out_lin.bias  |          0           |    768     |\n",
      "|   distilbert.transformer.layer.4.sa_layer_norm.weight   |         768          |    768     |\n",
      "|    distilbert.transformer.layer.4.sa_layer_norm.bias    |         768          |    768     |\n",
      "|      distilbert.transformer.layer.4.ffn.lin1.weight     |          0           |  2359296   |\n",
      "|       distilbert.transformer.layer.4.ffn.lin1.bias      |          0           |    3072    |\n",
      "|      distilbert.transformer.layer.4.ffn.lin2.weight     |          0           |  2359296   |\n",
      "|       distilbert.transformer.layer.4.ffn.lin2.bias      |          0           |    768     |\n",
      "| distilbert.transformer.layer.4.output_layer_norm.weight |         768          |    768     |\n",
      "|  distilbert.transformer.layer.4.output_layer_norm.bias  |         768          |    768     |\n",
      "|  distilbert.transformer.layer.5.attention.q_lin.weight  |          0           |   589824   |\n",
      "|   distilbert.transformer.layer.5.attention.q_lin.bias   |          0           |    768     |\n",
      "|  distilbert.transformer.layer.5.attention.k_lin.weight  |          0           |   589824   |\n",
      "|   distilbert.transformer.layer.5.attention.k_lin.bias   |          0           |    768     |\n",
      "|  distilbert.transformer.layer.5.attention.v_lin.weight  |          0           |   589824   |\n",
      "|   distilbert.transformer.layer.5.attention.v_lin.bias   |          0           |    768     |\n",
      "| distilbert.transformer.layer.5.attention.out_lin.weight |          0           |   589824   |\n",
      "|  distilbert.transformer.layer.5.attention.out_lin.bias  |          0           |    768     |\n",
      "|   distilbert.transformer.layer.5.sa_layer_norm.weight   |         768          |    768     |\n",
      "|    distilbert.transformer.layer.5.sa_layer_norm.bias    |         768          |    768     |\n",
      "|      distilbert.transformer.layer.5.ffn.lin1.weight     |          0           |  2359296   |\n",
      "|       distilbert.transformer.layer.5.ffn.lin1.bias      |          0           |    3072    |\n",
      "|      distilbert.transformer.layer.5.ffn.lin2.weight     |          0           |  2359296   |\n",
      "|       distilbert.transformer.layer.5.ffn.lin2.bias      |          0           |    768     |\n",
      "| distilbert.transformer.layer.5.output_layer_norm.weight |         768          |    768     |\n",
      "|  distilbert.transformer.layer.5.output_layer_norm.bias  |         768          |    768     |\n",
      "|                  pre_classifier.weight                  |          0           |   589824   |\n",
      "|                   pre_classifier.bias                   |          0           |    768     |\n",
      "|                    classifier.weight                    |         1536         |    1536    |\n",
      "|                     classifier.bias                     |          2           |     2      |\n",
      "+---------------------------------------------------------+----------------------+------------+\n",
      "Total Trainable Params: 21506\n",
      "Percentage of trainable parameters: 0.00032120075853920416\n"
     ]
    },
    {
     "data": {
      "text/plain": "21506"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_trainable(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text, token_type_ids, __index_level_0__, index. If text, token_type_ids, __index_level_0__, index are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/Users/fionamuntwyler/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 160000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25000\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='25000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [    2/25000 : < :, Epoch 0.00/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "Input \u001B[0;32mIn [15]\u001B[0m, in \u001B[0;36m<cell line: 26>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     17\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[1;32m     18\u001B[0m     model,\n\u001B[1;32m     19\u001B[0m     training_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     23\u001B[0m     compute_metrics\u001B[38;5;241m=\u001B[39mcompute_metrics\n\u001B[1;32m     24\u001B[0m )\n\u001B[0;32m---> 26\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/transformers/trainer.py:1409\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1406\u001B[0m inner_training_loop \u001B[38;5;241m=\u001B[39m find_executable_batch_size(\n\u001B[1;32m   1407\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inner_training_loop, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_batch_size, args\u001B[38;5;241m.\u001B[39mauto_find_batch_size\n\u001B[1;32m   1408\u001B[0m )\n\u001B[0;32m-> 1409\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1410\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1411\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1412\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1413\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1414\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/transformers/trainer.py:1651\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   1650\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1651\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1653\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   1654\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[1;32m   1655\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_tpu_available()\n\u001B[1;32m   1656\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[1;32m   1657\u001B[0m ):\n\u001B[1;32m   1658\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/transformers/trainer.py:2345\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[0;34m(self, model, inputs)\u001B[0m\n\u001B[1;32m   2344\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss_context_manager():\n\u001B[0;32m-> 2345\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mn_gpu \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/transformers/trainer.py:2377\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[0;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[1;32m   2376\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 2377\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2378\u001B[0m \u001B[38;5;66;03m# Save past state if it exists\u001B[39;00m\n\u001B[1;32m   2379\u001B[0m \u001B[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:747\u001B[0m, in \u001B[0;36mDistilBertForSequenceClassification.forward\u001B[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    745\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[0;32m--> 747\u001B[0m distilbert_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistilbert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    748\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    749\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    750\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    751\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    752\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    753\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    754\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    755\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    756\u001B[0m hidden_state \u001B[38;5;241m=\u001B[39m distilbert_output[\u001B[38;5;241m0\u001B[39m]  \u001B[38;5;66;03m# (bs, seq_len, dim)\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:567\u001B[0m, in \u001B[0;36mDistilBertModel.forward\u001B[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    566\u001B[0m     inputs_embeds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(input_ids)  \u001B[38;5;66;03m# (bs, seq_length, dim)\u001B[39;00m\n\u001B[0;32m--> 567\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    568\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    569\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattn_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    570\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    571\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    572\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    573\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    574\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:345\u001B[0m, in \u001B[0;36mTransformer.forward\u001B[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    343\u001B[0m     all_hidden_states \u001B[38;5;241m=\u001B[39m all_hidden_states \u001B[38;5;241m+\u001B[39m (hidden_state,)\n\u001B[0;32m--> 345\u001B[0m layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattn_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattn_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    348\u001B[0m hidden_state \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:299\u001B[0m, in \u001B[0;36mTransformerBlock.forward\u001B[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001B[0m\n\u001B[1;32m    298\u001B[0m \u001B[38;5;66;03m# Feed Forward Network\u001B[39;00m\n\u001B[0;32m--> 299\u001B[0m ffn_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mffn\u001B[49m\u001B[43m(\u001B[49m\u001B[43msa_output\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# (bs, seq_length, dim)\u001B[39;00m\n\u001B[1;32m    300\u001B[0m ffn_output: torch\u001B[38;5;241m.\u001B[39mTensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_layer_norm(ffn_output \u001B[38;5;241m+\u001B[39m sa_output)  \u001B[38;5;66;03m# (bs, seq_length, dim)\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:244\u001B[0m, in \u001B[0;36mFFN.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    243\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[0;32m--> 244\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mapply_chunking_to_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mff_chunk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchunk_size_feed_forward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseq_len_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/transformers/pytorch_utils.py:241\u001B[0m, in \u001B[0;36mapply_chunking_to_forward\u001B[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001B[0m\n\u001B[1;32m    239\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcat(output_chunks, dim\u001B[38;5;241m=\u001B[39mchunk_dim)\n\u001B[0;32m--> 241\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minput_tensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:249\u001B[0m, in \u001B[0;36mFFN.ff_chunk\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    248\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation(x)\n\u001B[0;32m--> 249\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlin2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    250\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(x)\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 103\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/executing/executing.py:317\u001B[0m, in \u001B[0;36mSource.executing\u001B[0;34m(cls, frame_or_tb)\u001B[0m\n\u001B[1;32m    316\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 317\u001B[0m     args \u001B[38;5;241m=\u001B[39m \u001B[43mexecuting_cache\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n",
      "\u001B[0;31mKeyError\u001B[0m: (<code object _call_impl at 0x114b8f660, file \"/Users/fionamuntwyler/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1104>, 4642633312, 58)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:1993\u001B[0m, in \u001B[0;36mInteractiveShell.showtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   1992\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1993\u001B[0m         stb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mInteractiveTB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstructured_traceback\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1994\u001B[0m \u001B[43m            \u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtb_offset\u001B[49m\n\u001B[1;32m   1995\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1997\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/IPython/core/ultratb.py:1118\u001B[0m, in \u001B[0;36mAutoFormattedTB.structured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1117\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtb \u001B[38;5;241m=\u001B[39m tb\n\u001B[0;32m-> 1118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mFormattedTB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstructured_traceback\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1119\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_lines_of_context\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/IPython/core/ultratb.py:1012\u001B[0m, in \u001B[0;36mFormattedTB.structured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1010\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose_modes:\n\u001B[1;32m   1011\u001B[0m     \u001B[38;5;66;03m# Verbose modes need a full traceback\u001B[39;00m\n\u001B[0;32m-> 1012\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVerboseTB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstructured_traceback\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1013\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_lines_of_context\u001B[49m\n\u001B[1;32m   1014\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1015\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMinimal\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/IPython/core/ultratb.py:865\u001B[0m, in \u001B[0;36mVerboseTB.structured_traceback\u001B[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m    864\u001B[0m \u001B[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 865\u001B[0m formatted_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat_exception_as_a_whole\u001B[49m\u001B[43m(\u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_lines_of_context\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    866\u001B[0m \u001B[43m                                                       \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    868\u001B[0m colors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mColors  \u001B[38;5;66;03m# just a shorthand + quicker name lookup\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/IPython/core/ultratb.py:799\u001B[0m, in \u001B[0;36mVerboseTB.format_exception_as_a_whole\u001B[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[1;32m    797\u001B[0m head \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_header(etype, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlong_header)\n\u001B[1;32m    798\u001B[0m records \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 799\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_records\u001B[49m\u001B[43m(\u001B[49m\u001B[43metb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_lines_of_context\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m etb \u001B[38;5;28;01melse\u001B[39;00m []\n\u001B[1;32m    800\u001B[0m )\n\u001B[1;32m    802\u001B[0m frames \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/IPython/core/ultratb.py:854\u001B[0m, in \u001B[0;36mVerboseTB.get_records\u001B[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[1;32m    849\u001B[0m options \u001B[38;5;241m=\u001B[39m stack_data\u001B[38;5;241m.\u001B[39mOptions(\n\u001B[1;32m    850\u001B[0m     before\u001B[38;5;241m=\u001B[39mbefore,\n\u001B[1;32m    851\u001B[0m     after\u001B[38;5;241m=\u001B[39mafter,\n\u001B[1;32m    852\u001B[0m     pygments_formatter\u001B[38;5;241m=\u001B[39mformatter,\n\u001B[1;32m    853\u001B[0m )\n\u001B[0;32m--> 854\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mstack_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFrameInfo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstack_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43metb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m[tb_offset:]\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/stack_data/core.py:565\u001B[0m, in \u001B[0;36mFrameInfo.stack_data\u001B[0;34m(cls, frame_or_tb, options, collapse_repeated_frames)\u001B[0m\n\u001B[1;32m    563\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m frame\u001B[38;5;241m.\u001B[39mf_code, lineno\n\u001B[0;32m--> 565\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m collapse_repeated(\n\u001B[1;32m    566\u001B[0m     stack,\n\u001B[1;32m    567\u001B[0m     mapper\u001B[38;5;241m=\u001B[39mmapper,\n\u001B[1;32m    568\u001B[0m     collapser\u001B[38;5;241m=\u001B[39mRepeatedFrames,\n\u001B[1;32m    569\u001B[0m     key\u001B[38;5;241m=\u001B[39m_frame_key,\n\u001B[1;32m    570\u001B[0m )\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/stack_data/utils.py:84\u001B[0m, in \u001B[0;36mcollapse_repeated\u001B[0;34m(lst, collapser, mapper, key)\u001B[0m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_highlighted:\n\u001B[0;32m---> 84\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mmap\u001B[39m(mapper, original_group)\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/stack_data/core.py:555\u001B[0m, in \u001B[0;36mFrameInfo.stack_data.<locals>.mapper\u001B[0;34m(f)\u001B[0m\n\u001B[1;32m    554\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmapper\u001B[39m(f):\n\u001B[0;32m--> 555\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/stack_data/core.py:520\u001B[0m, in \u001B[0;36mFrameInfo.__init__\u001B[0;34m(self, frame_or_tb, options)\u001B[0m\n\u001B[1;32m    515\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m    516\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    517\u001B[0m         frame_or_tb: Union[FrameType, TracebackType],\n\u001B[1;32m    518\u001B[0m         options: Optional[Options] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    519\u001B[0m ):\n\u001B[0;32m--> 520\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexecuting \u001B[38;5;241m=\u001B[39m \u001B[43mSource\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecuting\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe_or_tb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    521\u001B[0m     frame, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlineno \u001B[38;5;241m=\u001B[39m frame_and_lineno(frame_or_tb)\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/executing/executing.py:369\u001B[0m, in \u001B[0;36mSource.executing\u001B[0;34m(cls, frame_or_tb)\u001B[0m\n\u001B[1;32m    367\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m source, node, stmts, decorator\n\u001B[0;32m--> 369\u001B[0m args \u001B[38;5;241m=\u001B[39m find(source\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfor_frame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe\u001B[49m\u001B[43m)\u001B[49m, retry_cache\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    370\u001B[0m executing_cache[key] \u001B[38;5;241m=\u001B[39m args\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/executing/executing.py:252\u001B[0m, in \u001B[0;36mSource.for_frame\u001B[0;34m(cls, frame, use_cache)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;124;03mReturns the `Source` object corresponding to the file the frame is executing in.\u001B[39;00m\n\u001B[1;32m    251\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m--> 252\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfor_filename\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf_code\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mco_filename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf_globals\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/executing/executing.py:270\u001B[0m, in \u001B[0;36mSource.for_filename\u001B[0;34m(cls, filename, module_globals, use_cache)\u001B[0m\n\u001B[1;32m    269\u001B[0m lines \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(linecache\u001B[38;5;241m.\u001B[39mgetlines(filename, module_globals))\n\u001B[0;32m--> 270\u001B[0m result \u001B[38;5;241m=\u001B[39m source_cache[filename] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_for_filename_and_lines\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlines\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/executing/executing.py:281\u001B[0m, in \u001B[0;36mSource._for_filename_and_lines\u001B[0;34m(cls, filename, lines)\u001B[0m\n\u001B[1;32m    279\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m--> 281\u001B[0m result \u001B[38;5;241m=\u001B[39m source_cache[(filename, lines)] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlines\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/stack_data/core.py:81\u001B[0m, in \u001B[0;36mSource.__init__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtree:\n\u001B[0;32m---> 81\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masttokens\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/executing/executing.py:413\u001B[0m, in \u001B[0;36mSource.asttokens\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    412\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01masttokens\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ASTTokens  \u001B[38;5;66;03m# must be installed separately\u001B[39;00m\n\u001B[0;32m--> 413\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mASTTokens\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    414\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    415\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtree\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtree\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    416\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    417\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/asttokens/asttokens.py:65\u001B[0m, in \u001B[0;36mASTTokens.__init__\u001B[0;34m(self, source_text, parse, tree, filename)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tree:\n\u001B[0;32m---> 65\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmark_tokens\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tree\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/asttokens/asttokens.py:76\u001B[0m, in \u001B[0;36mASTTokens.mark_tokens\u001B[0;34m(self, root_node)\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;66;03m# The hard work of this class is done by MarkTokens\u001B[39;00m\n\u001B[0;32m---> 76\u001B[0m \u001B[43mMarkTokens\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvisit_tree\u001B[49m\u001B[43m(\u001B[49m\u001B[43mroot_node\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/asttokens/mark_tokens.py:49\u001B[0m, in \u001B[0;36mMarkTokens.visit_tree\u001B[0;34m(self, node)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iter_children \u001B[38;5;241m=\u001B[39m util\u001B[38;5;241m.\u001B[39miter_children_func(node)\n\u001B[0;32m---> 49\u001B[0m \u001B[43mutil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvisit_tree\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_visit_before_children\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_visit_after_children\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/asttokens/util.py:201\u001B[0m, in \u001B[0;36mvisit_tree\u001B[0;34m(node, previsit, postvisit)\u001B[0m\n\u001B[1;32m    200\u001B[0m ins \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(stack)\n\u001B[0;32m--> 201\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m iter_children(current):\n\u001B[1;32m    202\u001B[0m   stack\u001B[38;5;241m.\u001B[39minsert(ins, (n, pvalue, _PREVISIT))\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/asttokens/util.py:98\u001B[0m, in \u001B[0;36miter_children_ast\u001B[0;34m(node)\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21miter_children_ast\u001B[39m(node):\n\u001B[1;32m     97\u001B[0m   \u001B[38;5;66;03m# Don't attempt to process children of JoinedStr nodes, which we can't fully handle yet.\u001B[39;00m\n\u001B[0;32m---> 98\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mis_joined_str\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/asttokens/util.py:142\u001B[0m, in \u001B[0;36mis_joined_str\u001B[0;34m(node)\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;66;03m# At the moment, nodes below JoinedStr have wrong line/col info, and trying to process them only\u001B[39;00m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;66;03m# leads to errors.\u001B[39;00m\n\u001B[0;32m--> 142\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__class__\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mJoinedStr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2014\u001B[0m, in \u001B[0;36mInteractiveShell.showtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2011\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_showtraceback(etype, value, stb)\n\u001B[1;32m   2013\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[0;32m-> 2014\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_exception_only\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m, file\u001B[38;5;241m=\u001B[39msys\u001B[38;5;241m.\u001B[39mstderr)\n",
      "File \u001B[0;32m~/PycharmProjects/twitter-sentiment-classification/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:1950\u001B[0m, in \u001B[0;36mInteractiveShell.get_exception_only\u001B[0;34m(self, exc_tuple)\u001B[0m\n\u001B[1;32m   1945\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1946\u001B[0m \u001B[38;5;124;03mReturn as a string (ending with a newline) the exception that\u001B[39;00m\n\u001B[1;32m   1947\u001B[0m \u001B[38;5;124;03mjust occurred, without any traceback.\u001B[39;00m\n\u001B[1;32m   1948\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1949\u001B[0m etype, value, tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_exc_info(exc_tuple)\n\u001B[0;32m-> 1950\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[43mtraceback\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat_exception_only\u001B[49m\u001B[43m(\u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1951\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(msg)\n",
      "File \u001B[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/traceback.py:140\u001B[0m, in \u001B[0;36mformat_exception_only\u001B[0;34m(etype, value)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mformat_exception_only\u001B[39m(etype, value):\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;124;03m\"\"\"Format the exception part of a traceback.\u001B[39;00m\n\u001B[1;32m    126\u001B[0m \n\u001B[1;32m    127\u001B[0m \u001B[38;5;124;03m    The arguments are the exception type and value such as given by\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    138\u001B[0m \n\u001B[1;32m    139\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(\u001B[43mTracebackException\u001B[49m\u001B[43m(\u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mformat_exception_only())\n",
      "File \u001B[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/traceback.py:523\u001B[0m, in \u001B[0;36mTracebackException.__init__\u001B[0;34m(self, exc_type, exc_value, exc_traceback, limit, lookup_lines, capture_locals, _seen)\u001B[0m\n\u001B[1;32m    521\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmsg \u001B[38;5;241m=\u001B[39m exc_value\u001B[38;5;241m.\u001B[39mmsg\n\u001B[1;32m    522\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m lookup_lines:\n\u001B[0;32m--> 523\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_lines\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/traceback.py:535\u001B[0m, in \u001B[0;36mTracebackException._load_lines\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    533\u001B[0m     frame\u001B[38;5;241m.\u001B[39mline\n\u001B[1;32m    534\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__context__:\n\u001B[0;32m--> 535\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__context__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_lines\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    536\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__cause__:\n\u001B[1;32m    537\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__cause__\u001B[38;5;241m.\u001B[39m_load_lines()\n",
      "File \u001B[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/traceback.py:533\u001B[0m, in \u001B[0;36mTracebackException._load_lines\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    531\u001B[0m \u001B[38;5;124;03m\"\"\"Private API. force all lines in the stack to be loaded.\"\"\"\u001B[39;00m\n\u001B[1;32m    532\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m frame \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstack:\n\u001B[0;32m--> 533\u001B[0m     \u001B[43mframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mline\u001B[49m\n\u001B[1;32m    534\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__context__:\n\u001B[1;32m    535\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__context__\u001B[38;5;241m.\u001B[39m_load_lines()\n",
      "File \u001B[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/traceback.py:288\u001B[0m, in \u001B[0;36mFrameSummary.line\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m    286\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mline\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_line \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_line \u001B[38;5;241m=\u001B[39m \u001B[43mlinecache\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetline\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlineno\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mstrip()\n\u001B[1;32m    289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_line\n",
      "File \u001B[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/linecache.py:16\u001B[0m, in \u001B[0;36mgetline\u001B[0;34m(filename, lineno, module_globals)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgetline\u001B[39m(filename, lineno, module_globals\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m---> 16\u001B[0m     lines \u001B[38;5;241m=\u001B[39m \u001B[43mgetlines\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodule_globals\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m lineno \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(lines):\n\u001B[1;32m     18\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m lines[lineno\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/linecache.py:55\u001B[0m, in \u001B[0;36mgetlines\u001B[0;34m(filename, module_globals)\u001B[0m\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m mod \u001B[38;5;129;01min\u001B[39;00m mods:\n\u001B[0;32m---> 55\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m__file__\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m \u001B[38;5;241m==\u001B[39m filename:\n\u001B[1;32m     56\u001B[0m         module_globals \u001B[38;5;241m=\u001B[39m mod\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m\n\u001B[1;32m     57\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(output_dir=DIR,\n",
    "                                  num_train_epochs=EPOCHS,\n",
    "                                  save_strategy=\"epoch\",\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  per_device_train_batch_size=BATCH_SIZE,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  metric_for_best_model=\"accuracy\")\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_pred = trainer.predict(val_tokenized)\n",
    "y_pred = np.argmax(val_pred.predictions, axis=1)\n",
    "y = val_tokenized.to_pandas()['label']\n",
    "metrics = evaluate(y, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "count_parameters(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datasets\n",
    "datasets.list_metrics()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}